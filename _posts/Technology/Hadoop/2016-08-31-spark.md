---
layout: post
title: Spark
category: 技术
tags: Hadoop
keywords: Spark
---

## 前言 (待整理)

mapreduce的不足

1. 复杂的计算需要大量的job完成
2. 依赖关系是由开发者自己管理的
3. 没有整理逻辑
4. 中间结果只能放在HDFS中
5. 对于实时数据处理的支持不够


## spark

||存储|提供操作|
|-|-|-|
|mapreduce|hdfs|map/reduce|
|sparck|RDD|transform,actiion|

RDD是一个分布式的内存抽象,我估计这是它支持的操作比mapreduce多的重要原因。当然，这个分布式内存抽象，大致也会经过mapreduce操作中shuffling等操作。

把数据当成对象，支持各种操作。


storm做的是流式处理，就是数据不停地来，storm一直在运行。hadoop和spark等则是批处理，等一批数据，处理一批数据。就是kafka、rabbit可以不停地接消息，storm可以不停地处理消息一样。

实时性和大数据量其实是不可兼得的，比如数据量很大的话，就要移动计算（而不是移动数据），这时实现实时性就比较困难。


## 源码分析
